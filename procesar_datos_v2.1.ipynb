{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RFSExZh5BbTcb9hh3CihDliHJwnS6hcv",
      "authorship_tag": "ABX9TyPGCROln0Qw/HuinI3vft8y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorge774/Procesamiento_datos/blob/main/procesar_datos_v2.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''procesar_datos.py\n",
        "   Este programa hace lo siguiente:\n",
        "   1.Reavisa la carpeta donde estan los archivos txt que genera janus luego de hacer adquisicion.\n",
        "   2.Revisa y toma los archivos txt que no ha leido anteriormente.\n",
        "   3.Toma el encabezado del archivo RunXX_list.txt con menor XX de todo el lote de archivos tomados en 2.\n",
        "   4.Toma como referencia temporal el 'Run start time' del encabezado tomado en 3.\n",
        "   5.Genera una estampa temporal para cada evento de todos los archivos RunXX_list.txt tomando como referencia a 4.\n",
        "   6.Genera un archivo 'MuTe_20240304_11h07m01s.txt'\n",
        "   7.Elimina aquellos eventos donde el conteo en todos los canales fue 0.\n",
        "   8.Elimina los archivos RunXX_list.txt\n",
        "\n",
        "   Los parametros de este programa son leidos en el archivo 'config.txt', los cuales son:\n",
        "   1.Ruta absoluta donde quedan los archivos txt que genera janus luego de hacer adquisicion.\n",
        "   2.Ruta absoluta donde quedaran los archivos 'MuTe_20240304_11h07m01s.txt'.\n",
        "   3.Numero de canales usados en la adquision.\n",
        "   4.Numero de lineas usadas en los encabezados de los archivos 'RunXX_list.txt'.\n",
        "\n",
        "   En el archivo 'vars.txt' el programa escribe el nombre de los archivos 'RunXX_list.txt' que va procesando.\n",
        "'''"
      ],
      "metadata": {
        "id": "tzXh47hUjytD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBsPiHLt0DOU"
      },
      "outputs": [],
      "source": [
        "print('procesando...')\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "from pytz import timezone\n",
        "import pandas as pd\n",
        "ini_exe=datetime.now(timezone('America/Bogota'))\n",
        "config_file=open(file='config.txt',mode='r');output_input_folders=config_file.read();config_file.close()\n",
        "num_header_lines=int(output_input_folders.split('\\n')[3].split('#')[0])#8\n",
        "n_channels=int(output_input_folders.split('\\n')[2].split('#')[0])#64 #numero de canales\n",
        "folder_path_caen=output_input_folders.split('\\n')[0].split('#')[0]\n",
        "output_folder_path=output_input_folders.split('\\n')[1].split('#')[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gestor de errores en los archivos run list\n",
        "\n",
        "#eliminar archivos.dat\n",
        "\n",
        "#ordenar los files_to_proces de acuerdo al run start time\n",
        "def key_function(file,folder_path_caen):\n",
        "    if re.search('list.txt',file):\n",
        "       file_path=folder_path_caen+'/'+file;file_to_proces=open(file=file_path,mode='r')\n",
        "       content=file_to_proces.readlines()[:10];file_to_proces.close()\n",
        "       string_date_time=''\n",
        "       for i in content[6].split()[4:-1]:i+=' ';string_date_time+=i\n",
        "       #datetime.strptime('Fri Mar 1 16:32:05 2024 ','%a %b %d %H:%M:%S %Y ')\n",
        "       ref_date_time=datetime.strptime(string_date_time,'%a %b %d %H:%M:%S %Y ')-timedelta(hours=5)\n",
        "       ref_date_time=pd.Timestamp(str(ref_date_time))\n",
        "       del content\n",
        "    if re.search('Info.txt',file):\n",
        "       file_path=folder_path_caen+'/'+file;file_to_proces=open(file=file_path,mode='r')\n",
        "       content=file_to_proces.readlines()[:10];file_to_proces.close()\n",
        "       ref_date_time=content[3].split()[2]+' '+content[3].split()[3]\n",
        "       ref_date_time=pd.Timestamp(datetime.strptime(ref_date_time,'%d/%m/%Y %H:%M'))\n",
        "       del content\n",
        "    #ignorar folders y archivos que no sean de info o corrida\n",
        "    if not re.search('list.txt',file) and not re.search('Info.txt',file):ref_date_time=pd.Timestamp('2030-01-01 00:00:00')\n",
        "    return ref_date_time\n",
        "\n",
        "#verificar que un archivo de corrida tenga informacion de todos los canales en todas las ventanas de adquision\n",
        "def check_arvhivo_corrida(file,folder_path_caen,num_header_lines,n_channels):\n",
        "    check=True#archivo de corrida sin errores\n",
        "    file_path=folder_path_caen+'/'+file;file_to_proces=open(file=file_path,mode='r')\n",
        "    data_and_header=file_to_proces.readlines();file_to_proces.close()\n",
        "    ini_index=num_header_lines+1\n",
        "    end_index=num_header_lines+n_channels+1\n",
        "    while ini_index<(len(data_and_header)-1):\n",
        "          #recorrer todos los data blocks de un archivo Runxx_list.txt\n",
        "          data_block=data_and_header[ini_index:end_index]\n",
        "          if len(data_block[0].split())!=5:\n",
        "             check=False#archivo de corrida con errores\n",
        "             os.remove(file_path)#eliminar archivo runxxlits.txt corrupto\n",
        "             print('archivo corrupto eliminado')\n",
        "             break\n",
        "          ini_index=end_index\n",
        "          end_index=ini_index+n_channels\n",
        "    del data_and_header\n",
        "    return check"
      ],
      "metadata": {
        "id": "y1TZ4wA-XioM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path_vars='vars.txt'\n",
        "##ini main loop\n",
        "vars_file=open(file=folder_path_vars,mode='r')\n",
        "processed_file_list=vars_file.read()\n",
        "vars_file.close()\n",
        "current_file_list=os.listdir(folder_path_caen)\n",
        "\n",
        "if processed_file_list:\n",
        "   #processed_file_list is not empty\n",
        "   files_to_proces=list(set(current_file_list)-set(processed_file_list.split('\\n')))#archivos que esten en folder_path_caen pero que no esten en el vars file\n",
        "else:\n",
        "   #processed_file_list is empty\n",
        "   files_to_proces=current_file_list\n",
        "\n",
        "files_to_proces.sort(key=lambda file:key_function(file,folder_path_caen))#ordenar los files_to_proces de acuerdo al run start time\n",
        "if files_to_proces:\n",
        "    #files_to_proces is not empty\n",
        "    count_files_run_list_processed=0\n",
        "    #'MuTe_20240304_11h07m01s'\n",
        "    output_file_path=''\n",
        "    gmt_5_datetime=datetime.now(timezone('America/Bogota'))\n",
        "    cur_h='0'+str(gmt_5_datetime.hour) if gmt_5_datetime.hour<10 else str(gmt_5_datetime.hour)\n",
        "    cur_day='0'+str(gmt_5_datetime.day) if gmt_5_datetime.day<10 else str(gmt_5_datetime.day)\n",
        "    cur_mon='0'+str(gmt_5_datetime.month) if gmt_5_datetime.month<10 else str(gmt_5_datetime.month)\n",
        "    cur_min='0'+str(gmt_5_datetime.minute) if gmt_5_datetime.minute<10 else str(gmt_5_datetime.minute)\n",
        "    cur_sec='0'+str(gmt_5_datetime.second) if gmt_5_datetime.second<10 else str(gmt_5_datetime.second)\n",
        "    name='MuTe_'+str(gmt_5_datetime.year)+cur_mon+cur_day+'_'+cur_h+'h'+cur_min+'m'+cur_sec+'s'+'.txt'\n",
        "    for file in files_to_proces:\n",
        "        if re.search('list.txt',file) and check_arvhivo_corrida(file,folder_path_caen,num_header_lines,n_channels):\n",
        "           #procesar los datos adquiridos\n",
        "           #se procesa un archivo Runxx_list.txt de files_to_proces\n",
        "           #ejecutar con cada archivo Runxx_list.txt\n",
        "           file_path=folder_path_caen+'/'+file\n",
        "           file_to_proces=open(file=file_path,mode='r')\n",
        "           data_and_header=file_to_proces.readlines()\n",
        "           file_to_proces.close()\n",
        "           output_file_path=output_folder_path+'/'+name\n",
        "           output_file=open(file=output_file_path,mode='a')\n",
        "\n",
        "           header=data_and_header[:num_header_lines]\n",
        "           if count_files_run_list_processed==0:\n",
        "              string_date_time=''\n",
        "              for i in header[6].split()[4:-1]:i+=' ';string_date_time+=i\n",
        "              #datetime.strptime('Fri Mar 1 16:32:05 2024 ','%a %b %d %H:%M:%S %Y ')\n",
        "              ref_date_time=datetime.strptime(string_date_time,'%a %b %d %H:%M:%S %Y ')-timedelta(hours=5)\n",
        "              ref_date_time=pd.Timestamp(str(ref_date_time))\n",
        "              delta_time=ref_date_time-ref_date_time\n",
        "              aux=['ch0'+str(i) if i<10 else 'ch'+str(i) for i in range(n_channels)]\n",
        "              aux2=[aux[i]+' ' if i!=(len(aux)-1) else aux[i] for i in range(len(aux))]\n",
        "              header2='Tstamp GMT-5(aa-mm-dd hh:mm:ss.ns) '\n",
        "              for i in aux2:header2+=i\n",
        "              output_file.write(header2+'\\n')\n",
        "           else:\n",
        "              string_date_time=''\n",
        "              for i in header[6].split()[4:-1]:i+=' ';string_date_time+=i\n",
        "              #datetime.strptime('Fri Mar 1 16:32:05 2024 ','%a %b %d %H:%M:%S %Y ')\n",
        "              last_date_time=datetime.strptime(string_date_time,'%a %b %d %H:%M:%S %Y ')-timedelta(hours=5)\n",
        "              last_date_time=pd.Timestamp(str(last_date_time))\n",
        "              delta_time=last_date_time-ref_date_time\n",
        "\n",
        "           ini_index=num_header_lines+1\n",
        "           end_index=num_header_lines+n_channels+1\n",
        "           while ini_index<(len(data_and_header)-1):\n",
        "                #recorrer todos los data blocks de un archivo Runxx_list.txt\n",
        "                data_block=data_and_header[ini_index:end_index]\n",
        "                #ejeutar para cada data block\n",
        "                ch_counts=[]\n",
        "                for i in range(len(data_block)):ch_counts.append(data_block[i].split()[-1])\n",
        "                if ch_counts.count('0')!=n_channels:#verificar que almenos un ch se haya activado\n",
        "                    Tstamp_us=data_block[0].split()[0]\n",
        "                    nanosegundos=(delta_time.total_seconds()*1e+9)+(float(Tstamp_us)*1000)\n",
        "                    Tstamp_gmt_5=ref_date_time+pd.Timedelta(nanosegundos,unit='ns')\n",
        "                    output_file.write(str(Tstamp_gmt_5))\n",
        "                    for _ in range(36-len(str(Tstamp_gmt_5))):output_file.write(' ')\n",
        "                    for i in range(len(data_block)):\n",
        "                        count=data_block[i].split()[-1]\n",
        "                        if i!=(len(data_block)-1):\n",
        "                           output_file.write(count)\n",
        "                           for _ in range(4+1-len(list(count))):output_file.write(' ')\n",
        "                        else:\n",
        "                           output_file.write(count+'\\n')\n",
        "                ini_index=end_index\n",
        "                end_index=ini_index+n_channels\n",
        "           output_file.close()\n",
        "           count_files_run_list_processed+=1\n",
        "           #os.remove(file_path)#eliminar archivo runxxlits.txt\n",
        "           del data_and_header#liberar memoria\n",
        "        if re.search('Info.txt',file):\n",
        "           #procesar metadata de los datos adquiridos\n",
        "           pass\n",
        "    if os.path.exists(output_file_path):\n",
        "       output_file=open(file=output_file_path,mode='r');content_output_file=output_file.readlines();output_file.close()\n",
        "       if not content_output_file[1:]:os.remove(output_file_path)#eliminar txt si esta vacio\n",
        "       del content_output_file\n",
        "    vars_file=open(file=folder_path_vars,mode='a')\n",
        "    if processed_file_list:\n",
        "       #processed_file_list is not empty\n",
        "       vars_file.write('\\n')\n",
        "       for i in range(0,len(files_to_proces)):\n",
        "           if i!=(len(files_to_proces)-1):\n",
        "              vars_file.write(files_to_proces[i]+'\\n')\n",
        "           else:\n",
        "              vars_file.write(files_to_proces[i])\n",
        "    else:\n",
        "      #processed_file_list is empty\n",
        "      for i in range(0,len(files_to_proces)):\n",
        "          if i!=(len(files_to_proces)-1):\n",
        "              vars_file.write(files_to_proces[i]+'\\n')\n",
        "          else:\n",
        "              vars_file.write(files_to_proces[i])\n",
        "    vars_file.close()\n",
        "print('Duracion del procesamiento:',(datetime.now(timezone('America/Bogota'))-ini_exe).total_seconds(),'segundos')\n",
        "##end main loop"
      ],
      "metadata": {
        "id": "Jqf5HT8fHxfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generar pixel map"
      ],
      "metadata": {
        "id": "BD53Df-MZ5mT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}